import streamlit as st
from snowflake.snowpark.functions import col, count

def dashboard():
    session = st.session_state.session
    DB_SCHEMA = st.session_state.db_schema
    
    st.title("ğŸ›¡ï¸ Data Quality Hub: All-in-One Editor")
    st.markdown("Cortex AIã¨ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§æ¤œçŸ¥ã•ã‚ŒãŸã€ä¿®æ­£ãŒå¿…è¦ãªé€šçŸ¥ã‚’ç®¡ç†ã—ã¾ã™ã€‚")
    
    # --- ãƒ‡ãƒ¼ã‚¿ã®å–å¾— ---
    log_table = session.table(f"{DB_SCHEMA}.ANOMALY_LOGS")
    unresolved_filter = (col("IS_RESOLVED") == False)
    
    # KPIè¡¨ç¤º
    total_anomalies = log_table.filter(unresolved_filter).count()
    rulebase_anomalies = log_table.filter(unresolved_filter & (col("ISSUE_TYPE") == "Rule-based")).count()
    ai_anomalies = log_table.filter(unresolved_filter & (col("ISSUE_TYPE") == "AI-based")).count()
    m1, m2, m3 = st.columns(3)      
    m1.metric("æœªå¯¾å¿œç·æ•°", f"{total_anomalies}ä»¶")
    m2.metric("ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹æ¤œçŸ¥", f"{rulebase_anomalies}ä»¶")
    m3.metric("AIæ¤œçŸ¥", f"{ai_anomalies}ä»¶")
    
    st.divider()

    # ã‚¿ãƒ–ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯
    object_counts = log_table.filter(unresolved_filter) \
        .group_by(col("TABLE_NAME")).agg(count("*").as_("COUNT")) \
        .to_pandas().set_index("TABLE_NAME")["COUNT"].to_dict()

    tables = ["LEADS", "OPPORTUNITIES", "ACCOUNTS", "PRODUCTS2"]
    tab_names = [f"{t} (â¬†ï¸ {object_counts.get(t, 0)}ä»¶)" for t in tables]
    
    # å±¥æ­´ã‚¿ãƒ–ã®è¿½åŠ 
    tables.append("âœ… ä¿®æ­£æ¸ˆã¿")
    tab_names.append("âœ… è§£æ±ºæ¸ˆã¿ï¼ˆå±¥æ­´ï¼‰")

    tabs = st.tabs(tab_names)
    
    for i, tab_content in enumerate(tabs):
        with tab_content:
            t_name = tables[i]
            
            if t_name == "âœ… ä¿®æ­£æ¸ˆã¿":
                df_resolved = log_table.filter(col("IS_RESOLVED") == True).to_pandas()
                st.dataframe(df_resolved, use_container_width=True, hide_index=True)
            else:
                # ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                filter_cond = (col("IS_RESOLVED") == False) & (col("TABLE_NAME") == t_name)
                df_anomalies = log_table.filter(filter_cond).order_by(col("DETECTED_AT").desc()).to_pandas()
                
                # --- ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ  ---
                # åˆæœŸçŠ¶æ…‹ã¯æœªé¸æŠ (False)
                selected_event = st.dataframe(
                    df_anomalies, 
                    use_container_width=True, 
                    hide_index=True, 
                    on_select="rerun", # é¸æŠæ™‚ã«å†å®Ÿè¡Œ
                    selection_mode="single-row", # å˜ä¸€è¡Œé¸æŠ
                    key=f"df_{t_name}"
                )

                # --- é¸æŠã•ã‚ŒãŸå ´åˆã®ã¿ä¿®æ­£ç”»é¢ã‚’è¡¨ç¤º ---
                if selected_event and len(selected_event["selection"]["rows"]) > 0:
                    # é¸æŠã•ã‚ŒãŸè¡Œã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
                    row_idx = selected_event["selection"]["rows"][0]
                    anomaly = df_anomalies.iloc[row_idx]
                    
                    st.divider()
                    st.subheader(f"ğŸ› ï¸ ä¿®æ­£ç”»é¢: {t_name}")
                    
                    # å®Ÿéš›ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—
                    target_table_path = f"{DB_SCHEMA}.{t_name}"
                    source_record = session.table(target_table_path).filter(col("ID") == anomaly['RECORD_ID']).to_pandas()
                    
                    if not source_record.empty:
                        record = source_record.iloc[0]
                        
                        # ä¿®æ­£ç”¨ãƒ•ã‚©ãƒ¼ãƒ 
                        with st.form(key=f"edit_form_{t_name}_{anomaly['RECORD_ID']}"):
                            st.write(f"**å¯¾è±¡ID**: `{anomaly['RECORD_ID']}`")
                            st.info(f"**AIæŒ‡æ‘˜**: {anomaly['AI_FEEDBACK']}")
                            
                            # ç·¨é›†ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆä¾‹: LEADSï¼‰
                            updated_data = {}
                            cols = st.columns(2)
                            
                            # ãƒ†ãƒ¼ãƒ–ãƒ«ã”ã¨ã®ã‚«ãƒ©ãƒ è¨­å®šï¼ˆå‹•çš„ã«èª¿æ•´å¯èƒ½ï¼‰
                            fields_to_edit = [c for c in source_record.columns if c not in ["ID", "CREATED_AT"]]
                            
                            for j, field in enumerate(fields_to_edit):
                                with cols[j % 2]:
                                    updated_data[field] = st.text_input(field, value=str(record[field]))
                            
                            if st.form_submit_button("âœ… å¤‰æ›´ã‚’ä¿å­˜ã—ã¦è§£æ±ºæ¸ˆã¿ã«ã™ã‚‹", type="primary"):
                                try:
                                    # 1. å…ƒãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ›´æ–°
                                    session.table(target_table_path).update(updated_data, col("ID") == anomaly['RECORD_ID'])
                                    # 2. ãƒ­ã‚°ã‚’è§£æ±ºæ¸ˆã¿ã«
                                    session.table(f"{DB_SCHEMA}.ANOMALY_LOGS").update(
                                        {"IS_RESOLVED": True},
                                        (col("TABLE_NAME") == t_name) & (col("RECORD_ID") == anomaly['RECORD_ID'])
                                    )
                                    st.success("æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                                    st.rerun() # ãƒªã‚¹ãƒˆã‚’æ›´æ–°ã™ã‚‹ãŸã‚ã«å†èµ·å‹•
                                except Exception as e:
                                    st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    else:
                        st.error("ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")